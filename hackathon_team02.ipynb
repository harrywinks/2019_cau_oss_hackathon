{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon_team02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrywinks/2019_cau_oss_hackathon/blob/master/hackathon_team02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lwEXhUqys1",
        "colab_type": "text"
      },
      "source": [
        "# **1. 초기 환경 설정**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zse-0iS0yADY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66MgsgP70f1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5qp6fWesEIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms5PBBJ1qSC6",
        "colab_type": "code",
        "outputId": "8a4d8d58-c9ef-488b-a82e-5cd13cf3c0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals\n",
        "\n",
        "# tensorflow와 tf.keras 및 관련 라이브러리 임포트\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "is_mnist = True;\n",
        "\n",
        "# 데이터셋 로드\n",
        "# x_train, y_train: 트레이닝 데이터 및 레이블\n",
        "# x_test, y_test: 테스트 데이터 및 레이블\n",
        "if is_mnist:\n",
        "  data_type = 'mnist'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data() # fashion MNIST 데이터셋인 경우,\n",
        "else:\n",
        "  data_type = 'cifar10'\n",
        "  (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data() # cifar10 데이터셋인 경우,\n",
        "\n",
        "\n",
        "# 분류를 위해 클래스 벡터를 바이너리 매트릭스로 변환\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "\n",
        "# 총 클래스 개수\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "# 인풋 데이터 타입\n",
        "input_shape = x_test.shape[1:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9c2KLDBIhNQ",
        "colab_type": "text"
      },
      "source": [
        "# **2. 데이터 전처리**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpCRpYqfsMTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, DepthwiseConv2D, SeparableConv2D\n",
        "from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D\n",
        "from tensorflow.keras.layers import BatchNormalization, concatenate, add, Dropout, ReLU, Lambda, Activation, LeakyReLU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jcyQZK6sQCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 전처리 (예: normalization)\n",
        "x_train_after = x_train / 255.0\n",
        "x_test_after = x_test / 255.0\n",
        "if is_mnist:\n",
        "  x_train_after=x_train_after.reshape(x_train_after.shape[0],28,28,1)\n",
        "  x_test_after=x_test_after.reshape(x_test_after.shape[0],28,28,1)\n",
        "  input_shape=x_test_after.shape[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqE7F4lHsTLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2777c0d-1247-4557-80f3-ef77d9ca7715"
      },
      "source": [
        "#실시간 데이터 확대로 텐서 이미지 데이터의 배치를 생성합니다. 데이터가 일괄 처리됩니다.\n",
        "from keras.preprocessing.image import ImageDataGenerator  \n",
        "datagen = ImageDataGenerator(\n",
        "    featurewise_center=True,\n",
        "    featurewise_std_normalization=True,\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.3,\n",
        "    height_shift_range=0.3,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "datagen.fit(x_train_after)\n",
        "\n",
        "type(x_train_after)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-YjppJpXBO9",
        "colab_type": "text"
      },
      "source": [
        "# **3. 모델 생성**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCsI8Of0Ze4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "#keras와 tensorflow.keras가 섞여서 집어넣은 코드\n",
        "import keras.backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Xo1Hv3vuWP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61a5ee2f-2332-4d7c-d25d-4df8f5ba6f95"
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 체크포인트 콜백 만들기\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 monitor='val_acc',\n",
        "                                                 save_best_only=True, \n",
        "                                                 save_weights_only=True,\n",
        "                                                 mode = 'max', \n",
        "                                                 verbose=0,\n",
        "                                                 period=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0824 08:50:44.162117 140623657674624 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FNhaiEts2tE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "outputId": "62709d36-2d0e-41d7-e157-4167c0e0441b"
      },
      "source": [
        "\n",
        "\n",
        "import keras.backend as K\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "\n",
        "\n",
        "droprate=0.25\n",
        "model = keras.Sequential()\n",
        "#convolution 1st layers\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\",\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape)) #0\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(droprate))#3\n",
        "#model.add(MaxPooling2D())\n",
        "\n",
        "#convolution 2nd layer\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))#1\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D())\n",
        "model.add(tf.keras.layers.Dropout(droprate))#3\n",
        "\n",
        "#convolution 3rd layers\n",
        "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'))#1\n",
        "model.add(BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D())\n",
        "model.add(tf.keras.layers.Dropout(droprate))#3\n",
        "\n",
        "#Fully connected 1st layers\n",
        "model.add(tf.keras.layers.Flatten()) #7\n",
        "model.add(tf.keras.layers.Dense(500,use_bias=False)) #13\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu')) #14\n",
        "model.add(tf.keras.layers.Dropout(droprate))      #15\n",
        "\n",
        "#Fully connected final layer\n",
        "model.add(tf.keras.layers.Dense(10)) #8f\n",
        "model.add(tf.keras.layers.Activation('softmax')) #9\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(), metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train_after, y_train, batch_size = 128,epochs = 15, shuffle=True,\n",
        "          validation_data=[x_test_after, y_test],callbacks = [cp_callback])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 11s 188us/sample - loss: 0.4330 - acc: 0.8428 - val_loss: 0.7016 - val_acc: 0.7729\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2888 - acc: 0.8943 - val_loss: 0.2862 - val_acc: 0.8968\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2514 - acc: 0.9079 - val_loss: 0.2700 - val_acc: 0.9021\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2259 - acc: 0.9176 - val_loss: 0.2517 - val_acc: 0.9084\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.2126 - acc: 0.9231 - val_loss: 0.2300 - val_acc: 0.9176\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1949 - acc: 0.9278 - val_loss: 0.2424 - val_acc: 0.9151\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1861 - acc: 0.9333 - val_loss: 0.2343 - val_acc: 0.9134\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1759 - acc: 0.9365 - val_loss: 0.2228 - val_acc: 0.9213\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1607 - acc: 0.9414 - val_loss: 0.2069 - val_acc: 0.9289\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1550 - acc: 0.9429 - val_loss: 0.2099 - val_acc: 0.9283\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1470 - acc: 0.9461 - val_loss: 0.2075 - val_acc: 0.9299\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1396 - acc: 0.9487 - val_loss: 0.2094 - val_acc: 0.9265\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 10s 172us/sample - loss: 0.1351 - acc: 0.9500 - val_loss: 0.2032 - val_acc: 0.9296\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1275 - acc: 0.9539 - val_loss: 0.2220 - val_acc: 0.9270\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 10s 173us/sample - loss: 0.1246 - acc: 0.9544 - val_loss: 0.2177 - val_acc: 0.9319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe50b7284e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR9WUYXxqtfR",
        "colab_type": "text"
      },
      "source": [
        "# **4. 모델 저장**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuVSJBUnveIG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi9yznz4qvzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team02'\n",
        "\n",
        "# 모델의 weight 값만 저장합니다.\n",
        "model.save_weights(save_path + 'model_weight_' + data_type + '_' + team_name + '.h5')\n",
        "\n",
        "# 모델의 구조만을 저장합니다.\n",
        "model_json = model.to_json()\n",
        "with open(save_path + 'model_structure_' + data_type + '_' + team_name + '.json', 'w') as json_file : \n",
        "    json_file.write(model_json)\n",
        "\n",
        "# 트레이닝된 전체 모델을 저장합니다.\n",
        "model.save(save_path +  'model_entire_' + data_type + '_' + team_name + '.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCqf7t0MtA82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B2BoRDZ7cFl",
        "colab_type": "text"
      },
      "source": [
        "# **5. 모델 로드 및 평가**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KkCxgV7xJAh",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDBwxVUx7knQ",
        "colab_type": "code",
        "outputId": "68c8606a-4846-4c7e-ae98-cfedf4312f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "save_path = '/content/'\n",
        "team_name = 'team02'\n",
        "\n",
        "model = keras.models.load_model(save_path + 'model_entire_' + data_type + '_' + team_name + '.h5')\n",
        "model.evaluate(x_test_after, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 112us/sample - loss: 0.2177 - acc: 0.9319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.21768041597157717, 0.9319]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}